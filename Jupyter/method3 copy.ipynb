{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验版本：\n",
    "> 1. pandas版本 0.19.2   ---  0.22.0\n",
    "> 2. numpy 版本 1.11.3   ---  1.14.5\n",
    "> 3. anaconda 4.3.0   \n",
    "> 4. sklearn版本 0.18.1  ---  0.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import matplotlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas 版本: 0.22.0\n",
      "NumPy 版本: 1.14.5\n",
      "Scikit-learn 版本: 0.19.2\n",
      "Matplotlib 版本: 2.1.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Pandas 版本:\", pd.__version__)\n",
    "print(\"NumPy 版本:\", np.__version__)\n",
    "print(\"Scikit-learn 版本:\", sklearn.__version__)\n",
    "print(\"Matplotlib 版本:\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集NSL-KDD和KDD-99\n",
    "\n",
    "> col——names :42个列名    \n",
    "> 训练集：KDDTrain--df   及其列名（xxx,42）    \n",
    "> 测试集：KDDTest--df_test    及其列名（xxx,42）    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据库的列名\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty_level\"]\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_path=r\"F:\\Jupyter\\kaggle\\data\\NSL-KDD\\KDDTrain+.txt\"\n",
    "test_path=r\"F:\\Jupyter\\kaggle\\data\\NSL-KDD\\KDDTest+.txt\"\n",
    "df = pd.read_csv(train_path, header=None, names = col_names)\n",
    "df_test = pd.read_csv(test_path, header=None, names = col_names)\n",
    "\n",
    "df.drop('difficulty_level',inplace=True,axis=1)\n",
    "df_test.drop('difficulty_level',inplace=True,axis=1)\n",
    "#数据集的shape\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>saint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>mscan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ          0          0     0   \n",
       "1         0           tcp   private   REJ          0          0     0   \n",
       "2         2           tcp  ftp_data    SF      12983          0     0   \n",
       "3         0          icmp     eco_i    SF         20          0     0   \n",
       "4         1           tcp    telnet  RSTO          0         15     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot   ...     dst_host_srv_count  \\\n",
       "0               0       0    0   ...                     10   \n",
       "1               0       0    0   ...                      1   \n",
       "2               0       0    0   ...                     86   \n",
       "3               0       0    0   ...                     57   \n",
       "4               0       0    0   ...                     86   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.04                    0.06   \n",
       "1                    0.00                    0.06   \n",
       "2                    0.61                    0.04   \n",
       "3                    1.00                    0.00   \n",
       "4                    0.31                    0.17   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.00                         0.00   \n",
       "1                         0.00                         0.00   \n",
       "2                         0.61                         0.02   \n",
       "3                         1.00                         0.28   \n",
       "4                         0.03                         0.02   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                  1.00   \n",
       "1                   0.0                       0.0                  1.00   \n",
       "2                   0.0                       0.0                  0.00   \n",
       "3                   0.0                       0.0                  0.00   \n",
       "4                   0.0                       0.0                  0.83   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      1.00  neptune  \n",
       "1                      1.00  neptune  \n",
       "2                      0.00   normal  \n",
       "3                      0.00    saint  \n",
       "4                      0.71    mscan  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                         int64\n",
       "protocol_type                   object\n",
       "service                         object\n",
       "flag                            object\n",
       "src_bytes                        int64\n",
       "dst_bytes                        int64\n",
       "land                             int64\n",
       "wrong_fragment                   int64\n",
       "urgent                           int64\n",
       "hot                              int64\n",
       "num_failed_logins                int64\n",
       "logged_in                        int64\n",
       "num_compromised                  int64\n",
       "root_shell                       int64\n",
       "su_attempted                     int64\n",
       "num_root                         int64\n",
       "num_file_creations               int64\n",
       "num_shells                       int64\n",
       "num_access_files                 int64\n",
       "num_outbound_cmds                int64\n",
       "is_host_login                    int64\n",
       "is_guest_login                   int64\n",
       "count                            int64\n",
       "srv_count                        int64\n",
       "serror_rate                    float64\n",
       "srv_serror_rate                float64\n",
       "rerror_rate                    float64\n",
       "srv_rerror_rate                float64\n",
       "same_srv_rate                  float64\n",
       "diff_srv_rate                  float64\n",
       "srv_diff_host_rate             float64\n",
       "dst_host_count                   int64\n",
       "dst_host_srv_count               int64\n",
       "dst_host_same_srv_rate         float64\n",
       "dst_host_diff_srv_rate         float64\n",
       "dst_host_same_src_port_rate    float64\n",
       "dst_host_srv_diff_host_rate    float64\n",
       "dst_host_serror_rate           float64\n",
       "dst_host_srv_serror_rate       float64\n",
       "dst_host_rerror_rate           float64\n",
       "dst_host_srv_rerror_rate       float64\n",
       "label                           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution of Training and Test set\n",
    "理论上测试集有23种label（22+1），训练集有38种\n",
    "df的label有23种    \n",
    "df_test的label有38种   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in Training set: 23\n",
      "Label distribution Training set:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Number of unique labels in Test set: 38\n",
      "Label distribution Test set:\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "xterm                13\n",
      "rootkit              13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "sqlattack             2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "worm                  2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_train = df['label'].nunique()\n",
    "num_test = df_test['label'].nunique()\n",
    "print('Number of unique labels in Training set:', num_train)\n",
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Number of unique labels in Test set:', num_test)\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 DataFrame（df）中每一列的缺失值数量。\n",
    "具体来说，df.isnull() 方法会返回一个布尔类型的 DataFrame，其中缺失值位置为 True，\n",
    "#非缺失值位置为 False。而 sum() 方法会对这个布尔类型的 DataFrame 进行求和操作，因为在 Python 中，True 被当作 1，False 被当作 0，所以最终的求和结果就是每列缺失值的数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       0\n",
       "protocol_type                  0\n",
       "service                        0\n",
       "flag                           0\n",
       "src_bytes                      0\n",
       "dst_bytes                      0\n",
       "land                           0\n",
       "wrong_fragment                 0\n",
       "urgent                         0\n",
       "hot                            0\n",
       "num_failed_logins              0\n",
       "logged_in                      0\n",
       "num_compromised                0\n",
       "root_shell                     0\n",
       "su_attempted                   0\n",
       "num_root                       0\n",
       "num_file_creations             0\n",
       "num_shells                     0\n",
       "num_access_files               0\n",
       "num_outbound_cmds              0\n",
       "is_host_login                  0\n",
       "is_guest_login                 0\n",
       "count                          0\n",
       "srv_count                      0\n",
       "serror_rate                    0\n",
       "srv_serror_rate                0\n",
       "rerror_rate                    0\n",
       "srv_rerror_rate                0\n",
       "same_srv_rate                  0\n",
       "diff_srv_rate                  0\n",
       "srv_diff_host_rate             0\n",
       "dst_host_count                 0\n",
       "dst_host_srv_count             0\n",
       "dst_host_same_srv_rate         0\n",
       "dst_host_diff_srv_rate         0\n",
       "dst_host_same_src_port_rate    0\n",
       "dst_host_srv_diff_host_rate    0\n",
       "dst_host_serror_rate           0\n",
       "dst_host_srv_serror_rate       0\n",
       "dst_host_rerror_rate           0\n",
       "dst_host_srv_rerror_rate       0\n",
       "label                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       0\n",
       "protocol_type                  0\n",
       "service                        0\n",
       "flag                           0\n",
       "src_bytes                      0\n",
       "dst_bytes                      0\n",
       "land                           0\n",
       "wrong_fragment                 0\n",
       "urgent                         0\n",
       "hot                            0\n",
       "num_failed_logins              0\n",
       "logged_in                      0\n",
       "num_compromised                0\n",
       "root_shell                     0\n",
       "su_attempted                   0\n",
       "num_root                       0\n",
       "num_file_creations             0\n",
       "num_shells                     0\n",
       "num_access_files               0\n",
       "num_outbound_cmds              0\n",
       "is_host_login                  0\n",
       "is_guest_login                 0\n",
       "count                          0\n",
       "srv_count                      0\n",
       "serror_rate                    0\n",
       "srv_serror_rate                0\n",
       "rerror_rate                    0\n",
       "srv_rerror_rate                0\n",
       "same_srv_rate                  0\n",
       "diff_srv_rate                  0\n",
       "srv_diff_host_rate             0\n",
       "dst_host_count                 0\n",
       "dst_host_srv_count             0\n",
       "dst_host_same_srv_rate         0\n",
       "dst_host_diff_srv_rate         0\n",
       "dst_host_same_src_port_rate    0\n",
       "dst_host_srv_diff_host_rate    0\n",
       "dst_host_serror_rate           0\n",
       "dst_host_srv_serror_rate       0\n",
       "dst_host_rerror_rate           0\n",
       "dst_host_srv_rerror_rate       0\n",
       "label                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: 数据预处理:\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别分类特征（一共有四个离散特征，分为两类——protocol_type，service，flag;和label）\n",
    ">protocol_type 有三种：TCP, UDP, ICMP \n",
    "\n",
    ">service：目标主机的网络服务类型，一共有七十种；训练集有66种，测试集有64种 \n",
    "\n",
    ">flag：一共有11种 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 70 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 23 categories\n",
      "Testing set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 64 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 38 categories\n"
     ]
    }
   ],
   "source": [
    "#  protocol_type (column 2), service (column 3), flag (column 4).这三个特征是离散的，非二进制的，\n",
    "# 遍历离散型特征\n",
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "print('Testing set:')        \n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## service : 目标主机的网络服务类型，离散类型，共有70种。\n",
    "aol, auth, bgp, courier, csnet_ns, ctf, daytime, discard, domain, domain_u, echo, eco_i, ecr_i, efs, exec, finger, ftp, ftp_data, gopher, harvest, hostnames, http, http_2784, http_443, http_8001, imap4, IRC, iso_tsap, klogin, kshell, ldap, link, login, mtp, name, netbios_dgm, netbios_ns, netbios_ssn, netstat, nnsp, nntp, ntp_u, other, pm_dump, pop_2, pop_3, printer, private, red_i, remote_job, rje, shell, smtp, sql_net, ssh, sunrpc, supdup, systat, telnet, tftp_u, tim_i, time, urh_i, urp_i, uucp, uucp_path, vmnet, whois, X11, Z39_50。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分离离散型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type   service flag\n",
       "0           tcp  ftp_data   SF\n",
       "1           udp     other   SF\n",
       "2           tcp   private   S0\n",
       "3           tcp      http   SF\n",
       "4           tcp      http   SF"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_categorical_values————存储了包含'protocol_type'，'service'和'flag'。的训练集数据\n",
    "#testdf_categorical_values——'protocol_type'，'service'和'flag'的测试集数据\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "\n",
    "categorical_columns=['protocol_type', 'service', 'flag'] \n",
    "#将这三个离散特征分离出来\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "df_categorical_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  protocol_type   service  flag\n",
       "0           tcp   private   REJ\n",
       "1           tcp   private   REJ\n",
       "2           tcp  ftp_data    SF\n",
       "3          icmp     eco_i    SF\n",
       "4           tcp    telnet  RSTO"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf_categorical_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对测试集和训练集每一种可能的取值都进行命名\n",
    "dumcols:含有这三个特征的训练集        \n",
    "testcumcols:有这三个特征的测试集        \n",
    "对于每个分类特征（'protocol_type'，'service'，'flag'），代码通过调用unique()方法获取其所有唯一值，然后使用sorted()函数对这些值进行排序。这样可以确保新的列名的顺序与独热编码后的列的顺序一致。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
     ]
    }
   ],
   "source": [
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "# 合并\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "print(dumcols)\n",
    "\n",
    "#同理于测试集，由于测试集和训练集只有service有区别，所以只要对service特别处理\n",
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用LabelEncoder()将离散特征转换为数字\n",
    "LabelEncoder会为每个类别分配一个唯一的整数。这些整数是按照类别的字母顺序分配的，从0开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n"
     ]
    }
   ],
   "source": [
    "#df_categorical_values_enc————将dumcols中的类别标签转换为数值。\n",
    "#testdf_categorical_values_enc同理\n",
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_categorical_values_enc.head())\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot-Encoding独热编码\n",
    "One-Hot-Encoding 独热编码，用于将所有分类特征转换为二元特征。    \n",
    "该转换器的输入应该是一个整数矩阵，表示分类（离散）特征的值。输出将是一个稀疏矩阵，其中每列对应一个特征的一个可能值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 对分类特征进行独热编码（One-Hot-Encoding）。首先，创建了一个OneHotEncoder对象enc。然后，使用 fit_transform方法对df_categorical_values_enc进行拟合和转换，结果存储在df_categorical_values_encenc中>。这个方法会返回一个稀疏矩阵，表示独热编码后的数据。\n",
    "接着，将独热编码后的数据转换为一个DataFrame，列名由dumcols指定。这样，每一列都对应一个原始的分类特征的一个类别，如果某个样本的该特征是该类别，那么对应的值为1，否则为0。\n",
    "对于测试集，也进行了同样的处理，只是列名由testdumcols指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol_type_icmp</th>\n",
       "      <th>Protocol_type_tcp</th>\n",
       "      <th>Protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>service_courier</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol_type_icmp  Protocol_type_tcp  Protocol_type_udp  service_IRC  \\\n",
       "0                 0.0                1.0                0.0          0.0   \n",
       "1                 0.0                0.0                1.0          0.0   \n",
       "2                 0.0                1.0                0.0          0.0   \n",
       "3                 0.0                1.0                0.0          0.0   \n",
       "4                 0.0                1.0                0.0          0.0   \n",
       "\n",
       "   service_X11  service_Z39_50  service_aol  service_auth  service_bgp  \\\n",
       "0          0.0             0.0          0.0           0.0          0.0   \n",
       "1          0.0             0.0          0.0           0.0          0.0   \n",
       "2          0.0             0.0          0.0           0.0          0.0   \n",
       "3          0.0             0.0          0.0           0.0          0.0   \n",
       "4          0.0             0.0          0.0           0.0          0.0   \n",
       "\n",
       "   service_courier   ...     flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  \\\n",
       "0              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "1              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "2              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "3              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "4              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "\n",
       "   flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \n",
       "0      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "4      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_cat_data----训练集每一行对于提取出来的每个特征作为列向量，若有这个特征就把值设为1，没有就是0\n",
    "# testdf_cat_data\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add  missing categories \n",
    "> 训练集和测试集中都有各自独有的属性，为了训练需要统一化；\n",
    "首先，代码从训练集df和测试集df_test的 DataFrame 中提取出 'service' 列，并将其转换为列表（tolist() 方法）。\n",
    "然后，使用 Python 的集合（set）操作找出训练集中存在但测试集中不存在的类别train_difference\n",
    "和测试集中存在但训练集中不存在的类别test_difference\n",
    "将这些新添加的类别的值全部设为0——————————————这样之后二者的维度和内容就完全可以对应上\n",
    "\n",
    "> 使用 join() 方法将 df 和 df_cat_data 合并为一个新的 DataFrame newdf。这个操作基于索引进行，也就是说，它会将 df_cat_data 中的列添加到 df 中，同时保持行索引的对应关系。然后，使用 drop() 方法删除 'flag'、'protocol_type' 和 'service' 这三列。这可能是因为这些列已经被编码并添加到数据框中，原始的列就不再需要了。\n",
    "对测试数据执行相同的操作：将 df_test 和 testdf_cat_data 合并，并删除 'flag'、'protocol_type' 和 'service' 这三列。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['service_red_i', 'service_aol', 'service_http_2784', 'service_urh_i', 'service_harvest', 'service_http_8001']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainservice = df['service'].tolist()\n",
    "testservice = df_test['service'].tolist()\n",
    "\n",
    "train_difference = list(set(trainservice) - set(testservice))\n",
    "test_difference = list(set(testservice) - set(trainservice))\n",
    "\n",
    "string = 'service_'\n",
    "train_difference = [string + x for x in train_difference]\n",
    "test_difference = [string + x for x in test_difference]\n",
    "\n",
    "print (train_difference)\n",
    "print(test_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 84)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in train_difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "for col in test_difference:\n",
    "    df_cat_data[col] = 0\n",
    "\n",
    "testdf_cat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 84)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将处理过的离散型特征与原本的数据型特征进行合并\n",
    "newdf--训练集\n",
    "newdf--test测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 123)\n",
      "(22544, 123)\n"
     ]
    }
   ],
   "source": [
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将数据集划分给四种攻击类别\n",
    "## 重命名五种类别: 0=normal, 1=DoS, 2=Probe, 3=R2L and 4=U2R.\n",
    "labeldf————从newdf中把label提取出来，使用replace函数（将离散转换为数值）————》得到newlabeldf，最后再赋回到newdf的label中    \n",
    "labeldf_test————同理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "\n",
    "#把.洗掉\n",
    "labeldf = labeldf.str.rstrip('.')\n",
    "labeldf_test = labeldf_test.str.rstrip('.')\n",
    "newlabeldf=labeldf.replace({'normal':0,\n",
    "                            'neptune':1,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, \n",
    "                             'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2,\n",
    "                             'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'worm': 3,\n",
    "                             'httptunnel': 4,'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({'normal' : 0,\n",
    "                             'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, \n",
    "                             'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2,\n",
    "                             'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'worm': 3,\n",
    "                             'httptunnel': 4,'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "# print(newdf['label'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: 特征缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分割为特征（X）和目标变量（Y）\n",
    "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
    "X = newdf.drop('label',axis=1)\n",
    "Y = newdf.label\n",
    "\n",
    "X_test = newdf_test.drop('label',axis=1)\n",
    "Y_test = newdf_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存功能名称列表以备后用（每个攻击类别都相同）。在此阶段将删除列名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colNames 就是一个包含 X_DoS 中所有列名称的列表\n",
    "colNames=list(X)\n",
    "colNames_test=list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集X中有特征方差为零的特征：\n",
      "特征名: num_outbound_cmds ，索引: 16\n"
     ]
    }
   ],
   "source": [
    "# 计算训练集X的特征方差\n",
    "variances_X = np.var(X, axis=0)\n",
    "\n",
    "# 计算测试集X_test的特征方差\n",
    "variances_X_test = np.var(X_test, axis=0)\n",
    "\n",
    "# 检查是否有特征方差为零\n",
    "zero_variance_features_X = np.where(variances_X == 0)[0]\n",
    "zero_variance_features_X_test = np.where(variances_X_test == 0)[0]\n",
    "\n",
    "if len(zero_variance_features_X) > 0:\n",
    "    print(\"训练集X中有特征方差为零的特征：\")\n",
    "    for idx in zero_variance_features_X:\n",
    "        print(\"特征名:\", colNames[idx], \"，索引:\", idx)\n",
    "        X.drop(X.columns[idx], axis=1, inplace=True)\n",
    "        X_test.drop(X.columns[idx], axis=1, inplace=True)        \n",
    "else:\n",
    "    print(\"训练集X中没有特征方差为零的特征。\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化：StandardScaler() \n",
    "``` python\n",
    "scaler1 = preprocessing.StandardScaler().fit(X_DoS) #这行代码创建了一个 StandardScaler 对象 scaler1，并使用 X_DoS 数据计算了均值和标准差。\n",
    "X_DoS=scaler1.transform(X_DoS) #这行代码将 scaler1 的缩放参数应用于 X_DoS，实现标准化。标准化后的数据将具有零均值和单位标准差,并将结果保存回 X_DoS。\n",
    "print(X_DoS.std(axis=0))#代码使用 std 函数检查了每种攻击类型的训练数据的标准差是否为1。如果数据已经正确地标准化，那么其标准差应该接近1。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 创建 MinMaxScaler 对象\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "\n",
    "# 对训练集特征进行缩放\n",
    "X_scaled_train = scaler1.fit_transform(X)\n",
    "\n",
    "# 对测试集特征进行缩放（使用训练集的缩放参数）\n",
    "X_scaled_test = scaler2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time 和 time 模块测量时间的方式不同，导致计算结果存在差异。\n",
    "%%time 魔术命令：\n",
    "%%time 是 Jupyter Notebook 或 IPython 环境中的一种方便的计时工具。\n",
    "它会自动测量代码块的执行时间，包括代码块中的所有操作（包括内部函数调用、循环等）。\n",
    "%%time 会考虑到代码块的整体执行时间，包括一切开销。\n",
    "由于它是自动计时的，因此不需要手动记录开始和结束时间戳。\n",
    "time 模块：\n",
    "time 模块是 Python 标准库中的一个模块，用于处理时间和日期。\n",
    "通过手动记录开始和结束时间戳，然后计算两者之间的差值，可以精确测量代码块的执行时间。\n",
    "但是，time 模块只会计算你明确指定的代码块的执行时间，不会包括其他操作的开销。\n",
    "因此，如果你在同一个代码块中同时使用了 %%time 和 time 模块，你会看到它们的计算结果存在差异。%%time 考虑了更多的因素，而 time 模块只计算了你明确指定的代码块的执行时间。\n",
    "\n",
    "如果你想要更精确的计时结果，建议使用 time 模块手动记录开始和结束时间戳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间: 0.19 秒\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "start_time = time.time()\n",
    "\n",
    "# all features\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, Y)\n",
    "end_time = time.time()\n",
    "# 计算执行时间\n",
    "training_time = end_time - start_time\n",
    "print(f\"训练时间: {training_time:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间: 0.44 秒\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6896</td>\n",
       "      <td>481</td>\n",
       "      <td>1967</td>\n",
       "      <td>204</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>5218</td>\n",
       "      <td>520</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>2346</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650</td>\n",
       "      <td>48</td>\n",
       "      <td>1581</td>\n",
       "      <td>235</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     1     2    3    4\n",
       "Actual attacks                               \n",
       "0                  6896   481  1967  204  163\n",
       "1                     0  1717  5218  520    3\n",
       "2                    66     5  2346    0    4\n",
       "3                   650    48  1581  235  240\n",
       "4                    50    13   111    7   19"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# 使用 cross_val_predict 进行交叉验证预测\n",
    "y_pred = cross_val_predict(clf, X_test, Y_test, cv=10)\n",
    "end_time = time.time()\n",
    "# 计算执行时间\n",
    "training_time = end_time - start_time\n",
    "print(f\"训练时间: {training_time:.2f} 秒\")\n",
    "# 混淆矩阵\n",
    "pd.crosstab(Y_test, y_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.900     0.710     0.794      9711\n",
      "          1      0.758     0.230     0.353      7458\n",
      "          2      0.209     0.969     0.344      2421\n",
      "          3      0.243     0.085     0.126      2754\n",
      "          4      0.044     0.095     0.060       200\n",
      "\n",
      "avg / total      0.691     0.497     0.512     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score,f1_score\n",
    "print(classification_report(Y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy\n",
      "0                 0.710123\n",
      "1                 0.230223\n",
      "2                 0.969021\n",
      "3                 0.085330\n",
      "4                 0.095000\n",
      "Overall Accuracy  0.497383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# 提取各分类的真正例、假正例、真负例、假负例\n",
    "true_positives = np.diag(conf_matrix)\n",
    "false_positives = np.sum(conf_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(conf_matrix, axis=1) - true_positives\n",
    "true_negatives = np.sum(conf_matrix) - (true_positives + false_positives + false_negatives)\n",
    "\n",
    "# 计算各分类的准确率\n",
    "class_accuracies = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "# 将整体准确率加入到列表中\n",
    "overall_accuracy = np.sum(true_positives) / np.sum(conf_matrix)\n",
    "\n",
    "# 创建包含准确率的数据帧\n",
    "index = [str(i) for i in range(len(class_accuracies))] + ['Overall Accuracy']\n",
    "df_ac = pd.DataFrame({'Accuracy': np.append(class_accuracies, overall_accuracy)}, index=index)\n",
    "\n",
    "# 打印数据帧\n",
    "print(df_ac)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
