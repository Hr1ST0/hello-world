{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as ss\n",
    "from scipy.special import digamma\n",
    "from math import log\n",
    "import numpy.random as nr\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Discrete estimators\n",
    "def entropyd(sx, base=2):\n",
    "    return entropyfromprobs(hist(sx), base=base)\n",
    "\n",
    "def midd(x, y):\n",
    "    return -entropyd(list(zip(x, y)))+entropyd(x)+entropyd(y)\n",
    "\n",
    "def hist(sx):\n",
    "    # Histogram from list of samples\n",
    "    d = dict()\n",
    "    for s in sx:\n",
    "        d[s] = d.get(s, 0) + 1\n",
    "    return map(lambda z: float(z)/len(sx), d.values())\n",
    "\n",
    "\n",
    "def entropyfromprobs(probs, base=2):\n",
    "    # Turn a normalized list of probabilities of discrete outcomes into entropy (base 2)\n",
    "    return -sum(map(elog, probs))/log(base)\n",
    "\n",
    "\n",
    "def elog(x):\n",
    "    # for entropy, 0 log 0 = 0. but we get an error for putting log 0\n",
    "    if x <= 0. or x >= 1.:\n",
    "        return 0\n",
    "    else:\n",
    "        return x*log(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(f1, f2):\n",
    "    ig = entropyd(f1) - conditional_entropy(f1, f2)\n",
    "    return ig\n",
    "\n",
    "\n",
    "def conditional_entropy(f1, f2):\n",
    "    ce = entropyd(f1) - midd(f1, f2)\n",
    "    return ce\n",
    "\n",
    "\n",
    "def su_calculation(f1, f2):\n",
    "    # calculate information gain of f1 and f2, t1 = ig(f1,f2)\n",
    "    t1 = information_gain(f1, f2)\n",
    "    # calculate entropy of f1, t2 = H(f1)\n",
    "    t2 = entropyd(f1)\n",
    "    # calculate entropy of f2, t3 = H(f2)\n",
    "    t3 = entropyd(f2)\n",
    "    # su(f1,f2) = 2*t1/(t2+t3)\n",
    "    su = 2.0*t1/(t2+t3)\n",
    "    return su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcbf(X, y, **kwargs):\n",
    "   \n",
    "\n",
    "    n_samples, n_features = X.shape\n",
    "    if 'delta' in kwargs.keys():\n",
    "        delta = kwargs['delta']\n",
    "    else:\n",
    "        # the default value of delta is 0\n",
    "        delta = 0\n",
    "\n",
    "    # t1[:,0] stores index of features, t1[:,1] stores symmetrical uncertainty of features\n",
    "    t1 = np.zeros((n_features, 2), dtype='object')\n",
    "    for i in range(n_features):\n",
    "        f = X[:, i]\n",
    "        t1[i, 0] = i\n",
    "        t1[i, 1] = su_calculation(f, y)\n",
    "    s_list = t1[t1[:, 1] > delta, :]\n",
    "    # index of selected features, initialized to be empty\n",
    "    F = []\n",
    "    # Symmetrical uncertainty of selected features\n",
    "    SU = []\n",
    "    while len(s_list) != 0:\n",
    "        # select the largest su inside s_list\n",
    "        idx = np.argmax(s_list[:, 1])\n",
    "        # record the index of the feature with the largest su\n",
    "        fp = X[:, s_list[idx, 0]]\n",
    "        np.delete(s_list, idx, 0)\n",
    "        F.append(s_list[idx, 0])\n",
    "        SU.append(s_list[idx, 1])\n",
    "        for i in s_list[:, 0]:\n",
    "            fi = X[:, i]\n",
    "            if su_calculation(fp, fi) >= t1[i, 1]:\n",
    "                # construct the mask for feature whose su is larger than su(fp,y)\n",
    "                idx = s_list[:, 0] != i\n",
    "                idx = np.array([idx, idx])\n",
    "                idx = np.transpose(idx)\n",
    "                # delete the feature by using the mask\n",
    "                s_list = s_list[idx]\n",
    "                length = len(s_list)//2\n",
    "                s_list = s_list.reshape((length, 2))\n",
    "    return np.array(F, dtype=int), np.array(SU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 42)\n",
      "Dimensions of the Test set: (22544, 42)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据库的列名\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty_level\"]\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_path=r\"F:\\Jupyter\\kaggle\\data\\NSL-KDD\\KDDTrain+.txt\"\n",
    "test_path=r\"F:\\Jupyter\\kaggle\\data\\NSL-KDD\\KDDTest+.txt\"\n",
    "df = pd.read_csv(train_path, header=None, names = col_names)\n",
    "df_test = pd.read_csv(test_path, header=None, names = col_names)\n",
    "df.drop('difficulty_level',inplace=True,axis=1)\n",
    "df_test.drop('difficulty_level',inplace=True,axis=1)\n",
    "#数据集的shape\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分离离散型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_categorical_values————存储了包含'protocol_type'，'service'和'flag'。的训练集数据\n",
    "#testdf_categorical_values——'protocol_type'，'service'和'flag'的测试集数据\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "\n",
    "categorical_columns=['protocol_type', 'service', 'flag'] \n",
    "#将这三个离散特征分离出来\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n"
     ]
    }
   ],
   "source": [
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "# 合并\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "print(dumcols)\n",
    "\n",
    "#同理于测试集，由于测试集和训练集只有service有区别，所以只要对service特别处理\n",
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n"
     ]
    }
   ],
   "source": [
    "#df_categorical_values_enc————将dumcols中的类别标签转换为数值。\n",
    "#testdf_categorical_values_enc同理\n",
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_categorical_values_enc.head())\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol_type_icmp</th>\n",
       "      <th>Protocol_type_tcp</th>\n",
       "      <th>Protocol_type_udp</th>\n",
       "      <th>service_IRC</th>\n",
       "      <th>service_X11</th>\n",
       "      <th>service_Z39_50</th>\n",
       "      <th>service_aol</th>\n",
       "      <th>service_auth</th>\n",
       "      <th>service_bgp</th>\n",
       "      <th>service_courier</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protocol_type_icmp  Protocol_type_tcp  Protocol_type_udp  service_IRC  \\\n",
       "0                 0.0                1.0                0.0          0.0   \n",
       "1                 0.0                0.0                1.0          0.0   \n",
       "2                 0.0                1.0                0.0          0.0   \n",
       "3                 0.0                1.0                0.0          0.0   \n",
       "4                 0.0                1.0                0.0          0.0   \n",
       "\n",
       "   service_X11  service_Z39_50  service_aol  service_auth  service_bgp  \\\n",
       "0          0.0             0.0          0.0           0.0          0.0   \n",
       "1          0.0             0.0          0.0           0.0          0.0   \n",
       "2          0.0             0.0          0.0           0.0          0.0   \n",
       "3          0.0             0.0          0.0           0.0          0.0   \n",
       "4          0.0             0.0          0.0           0.0          0.0   \n",
       "\n",
       "   service_courier   ...     flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR  \\\n",
       "0              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "1              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "2              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "3              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "4              0.0   ...          0.0        0.0          0.0        0.0   \n",
       "\n",
       "   flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  \n",
       "0      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0  \n",
       "3      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "4      0.0      0.0      0.0      0.0      1.0      0.0  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_cat_data----训练集每一行对于提取出来的每个特征作为列向量，若有这个特征就把值设为1，没有就是0\n",
    "# testdf_cat_data\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aol', 'urh_i', 'harvest', 'red_i', 'http_8001', 'http_2784']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "trainservice = df['service'].tolist()\n",
    "testservice = df_test['service'].tolist()\n",
    "\n",
    "train_difference = list(set(trainservice) - set(testservice))\n",
    "test_difference = list(set(testservice) - set(trainservice))\n",
    "\n",
    "print(train_difference)\n",
    "print(test_difference)\n",
    "\n",
    "string = 'service_'\n",
    "train_difference = [string + x for x in train_difference]\n",
    "test_difference = [string + x for x in test_difference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "for col in test_difference:\n",
    "    df_cat_data[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 123)\n",
      "(22544, 123)\n"
     ]
    }
   ],
   "source": [
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "\n",
    "#把.洗掉\n",
    "labeldf = labeldf.str.rstrip('.')\n",
    "labeldf_test = labeldf_test.str.rstrip('.')\n",
    "newlabeldf=labeldf.replace({'normal':0,\n",
    "                            'neptune':1,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, \n",
    "                             'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2,\n",
    "                             'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'worm': 3,\n",
    "                             'httptunnel': 4,'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({'normal' : 0,\n",
    "                             'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, \n",
    "                             'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2,\n",
    "                             'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'worm': 3,\n",
    "                             'httptunnel': 4,'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "# print(newdf['label'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of DoS: (125973, 123)\n",
      "Dimensions of DoS: (22544, 123)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of DoS:' ,newdf.shape)\n",
    "print('Dimensions of DoS:' ,newdf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration', 'wrong_fragment', 'dst_host_rerror_rate', 'srv_count', 'service_private', 'service_domain_u', 'service_smtp', 'service_ecr_i', 'dst_host_same_srv_rate', 'dst_host_count', 'flag_SF', 'service_telnet', 'is_guest_login', 'service_pm_dump', 'root_shell', 'dst_host_serror_rate', 'Protocol_type_tcp', 'Protocol_type_icmp', 'src_bytes', 'service_eco_i', 'service_finger', 'dst_bytes', 'dst_host_srv_rerror_rate', 'service_urp_i', 'logged_in', 'dst_host_same_src_port_rate', 'dst_host_srv_count', 'dst_host_diff_srv_rate', 'count', 'service_http']\n"
     ]
    }
   ],
   "source": [
    "combined_features=['duration', 'wrong_fragment', 'dst_host_rerror_rate', 'srv_count', \n",
    "                   'service_private', 'service_domain_u', 'service_smtp', 'service_ecr_i', \n",
    "                   'dst_host_same_srv_rate', 'dst_host_count', 'flag_SF', 'service_telnet', \n",
    "                   'is_guest_login', 'service_pm_dump', 'root_shell', 'dst_host_serror_rate', \n",
    "                   'Protocol_type_tcp', 'Protocol_type_icmp', 'src_bytes', 'service_eco_i',\n",
    "                     'service_finger', 'dst_bytes', 'dst_host_srv_rerror_rate', 'service_urp_i',\n",
    "                       'logged_in', 'dst_host_same_src_port_rate', 'dst_host_srv_count', \n",
    "                       'dst_host_diff_srv_rate', 'count', 'service_http']\n",
    "\n",
    "\n",
    "# 将并集转换为列表，以便输出到新变量中\n",
    "combined_features_list = list(combined_features)\n",
    "\n",
    "# 输出到新变量column中\n",
    "column = combined_features_list\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column列表中的项数为: 30\n"
     ]
    }
   ],
   "source": [
    "# 计算列表长度\n",
    "num_items = len(column)\n",
    "\n",
    "# 输出列表中的项数\n",
    "print(\"column列表中的项数为:\", num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分割为特征（X）和目标变量（Y）\n",
    "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
    "X_RFE = newdf[combined_features_list]\n",
    "Y_RFE = newdf.label\n",
    "\n",
    "X_test_RFE = newdf_test[combined_features_list]\n",
    "Y_test_RFE = newdf_test.label\n",
    "#colNames 就是一个包含 X 中所有列名称的列表\n",
    "colNames=list(X_RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#全部特征\n",
    "scaler8 = preprocessing.StandardScaler().fit(X_RFE)\n",
    "X_RFE=scaler8.transform(X_RFE) \n",
    "\n",
    "scaler9 = preprocessing.StandardScaler().fit(X_test_RFE)\n",
    "X_test_RFE=scaler9.transform(X_test_RFE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE（递归特征消除）：\n",
    "RFE 是一种特征选择方法，它通过逐步剔除不重要的特征来选择最优的特征子集。\n",
    "在 NSL-KDD 数据集中，您可以使用 RFE 来排除那些对入侵检测任务不太相关的特征。\n",
    "PCA（主成分分析）：\n",
    "PCA 是一种降维技术，它将高维数据映射到低维空间，保留最重要的特征。\n",
    "在 NSL-KDD 数据集中，您可以使用 PCA 来减少特征的维度，同时保留数据的主要信息。\n",
    "结合方法：\n",
    "首先，使用 RFE 从 NSL-KDD 数据集中选择一部分特征，这些特征对入侵检测任务有较高的相关性。\n",
    "然后，将选定的特征输入到 PCA 中，将其映射到低维空间。\n",
    "最终，您将得到一个具有较少特征且保留主要信息的数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 18, 29,  4, 19, 12, 14, 13])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_feature_indices=fcbf(X_RFE, Y_RFE)[0]\n",
    "selected_feature_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flag_SF', 'src_bytes', 'service_http', 'service_private', 'service_eco_i', 'is_guest_login', 'root_shell', 'service_pm_dump']\n"
     ]
    }
   ],
   "source": [
    "selected_colnames = [colNames[i] for i in selected_feature_indices]\n",
    "\n",
    "print(selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分割为特征（X）和目标变量（Y）\n",
    "# assign X as a dataframe of feautures and Y as a series of outcome variables\n",
    "X_FCBF = newdf[selected_colnames]\n",
    "Y_FCBF = newdf.label\n",
    "\n",
    "X_test_FCBF = newdf_test[selected_colnames]\n",
    "Y_test_FCBF = newdf_test.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#全部特征\n",
    "scaler10 = preprocessing.StandardScaler().fit(X_FCBF)\n",
    "X_FCBF=scaler10.transform(X_FCBF) \n",
    "\n",
    "scaler11 = preprocessing.StandardScaler().fit(X_test_FCBF)\n",
    "X_test_FCBF=scaler11.transform(X_test_FCBF) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间: 0.06 秒\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "start_time = time.time()\n",
    "\n",
    "clf=DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_FCBF, Y_FCBF)\n",
    "end_time = time.time()\n",
    "# 计算执行时间\n",
    "training_time = end_time - start_time\n",
    "print(f\"训练时间: {training_time:.2f} 秒\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练时间: 0.10 秒\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted attacks</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual attacks</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9252</td>\n",
       "      <td>184</td>\n",
       "      <td>152</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>7446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1765</td>\n",
       "      <td>644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2467</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted attacks     0     1    2     3   4\n",
       "Actual attacks                              \n",
       "0                  9252   184  152   107  16\n",
       "1                    12  7446    0     0   0\n",
       "2                    11  1765  644     1   0\n",
       "3                   269    10    2  2467   6\n",
       "4                    23   115    0     6  56"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# 使用 cross_val_predict 进行交叉验证预测start_time = time.time()\n",
    "start_time = time.time()\n",
    "y_pred = cross_val_predict(clf, X_test_FCBF, Y_test_FCBF, cv=10)\n",
    "\n",
    "end_time = time.time()\n",
    "# 计算执行时间\n",
    "training_time = end_time - start_time\n",
    "print(f\"训练时间: {training_time:.2f} 秒\")\n",
    "# 混淆矩阵\n",
    "pd.crosstab(Y_test_FCBF, y_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.967     0.953     0.960      9711\n",
      "          1      0.782     0.998     0.877      7458\n",
      "          2      0.807     0.266     0.400      2421\n",
      "          3      0.956     0.896     0.925      2754\n",
      "          4      0.718     0.280     0.403       200\n",
      "\n",
      "avg / total      0.885     0.881     0.863     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,roc_auc_score,f1_score\n",
    "print(classification_report(Y_test_FCBF, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Accuracy\n",
      "0                 0.952734\n",
      "1                 0.998391\n",
      "2                 0.266006\n",
      "3                 0.895788\n",
      "4                 0.280000\n",
      "Overall Accuracy  0.881166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(Y_test_FCBF, y_pred)\n",
    "\n",
    "# 提取各分类的真正例、假正例、真负例、假负例\n",
    "true_positives = np.diag(conf_matrix)\n",
    "false_positives = np.sum(conf_matrix, axis=0) - true_positives\n",
    "false_negatives = np.sum(conf_matrix, axis=1) - true_positives\n",
    "true_negatives = np.sum(conf_matrix) - (true_positives + false_positives + false_negatives)\n",
    "\n",
    "# 计算各分类的准确率\n",
    "class_accuracies = true_positives / (true_positives + false_negatives)\n",
    "\n",
    "# 将整体准确率加入到列表中\n",
    "overall_accuracy = np.sum(true_positives) / np.sum(conf_matrix)\n",
    "\n",
    "# 创建包含准确率的数据帧\n",
    "index = [str(i) for i in range(len(class_accuracies))] + ['Overall Accuracy']\n",
    "df_ac = pd.DataFrame({'Accuracy': np.append(class_accuracies, overall_accuracy)}, index=index)\n",
    "\n",
    "# 打印数据帧\n",
    "print(df_ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
